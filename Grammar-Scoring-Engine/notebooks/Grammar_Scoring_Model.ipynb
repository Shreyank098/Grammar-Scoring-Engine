{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "503a25d9", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "import os\nimport pandas as pd\nimport numpy as np\nimport librosa\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nimport joblib", "outputs": []}, {"id": "7ee43c43", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "train_csv_path = '../data/train.csv'\ntest_csv_path = '../data/test.csv'\ntrain_audio_dir = '../data/audios/train'\ntest_audio_dir = '../data/audios/test'\n\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)\n\nprint(\"Train Data Sample:\")\nprint(train_df.head())\nprint(\"Test Data Sample:\")\nprint(test_df.head())", "outputs": []}, {"id": "948e1cef", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "def extract_features(file_path):\n    audio, sr = librosa.load(file_path, sr=None)\n    \n    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n    contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n    zcr = librosa.feature.zero_crossing_rate(y=audio)\n    rmse = librosa.feature.rms(y=audio)\n    \n    features = np.hstack([\n        np.mean(mfcc, axis=1),\n        np.mean(chroma, axis=1),\n        np.mean(contrast, axis=1),\n        np.mean(zcr),\n        np.mean(rmse)\n    ])\n    return features", "outputs": []}, {"id": "f9fbdc57", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "X_train = []\ny_train = []\n\nfor idx, row in train_df.iterrows():\n    file_path = os.path.join(train_audio_dir, row['filename'])\n    features = extract_features(file_path)\n    X_train.append(features)\n    y_train.append(row['label'])\n\nX_train = np.array(X_train)\ny_train = np.array(y_train)", "outputs": []}, {"id": "cb8e2607", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\nmodel = RandomForestRegressor(n_estimators=150, random_state=42)\nmodel.fit(X_train_scaled, y_train)\n\ntrain_preds = model.predict(X_train_scaled)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\nprint(f\"Training RMSE: {train_rmse:.4f}\")", "outputs": []}, {"id": "0722928f", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "kf = KFold(n_splits=5, shuffle=True, random_state=42)\ncv_rmse = np.sqrt(-cross_val_score(model, X_train_scaled, y_train, cv=kf, scoring='neg_mean_squared_error'))\nprint(f\"Cross-validated RMSE: {cv_rmse.mean():.4f}\")", "outputs": []}, {"id": "9944df5a", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "X_test = []\ntest_filenames = []\n\nfor idx, row in test_df.iterrows():\n    file_path = os.path.join(test_audio_dir, row['filename'])\n    features = extract_features(file_path)\n    X_test.append(features)\n    test_filenames.append(row['filename'])\n\nX_test = np.array(X_test)\nX_test_scaled = scaler.transform(X_test)", "outputs": []}, {"id": "0e3717a3", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "test_preds = model.predict(X_test_scaled)\n\nsubmission = pd.DataFrame({\n    'filename': test_filenames,\n    'label': test_preds\n})\nsubmission_path = '../submission.csv'\nsubmission.to_csv(submission_path, index=False)\nprint(f\"Submission file saved to: {submission_path}\")", "outputs": []}, {"id": "2be142d1", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "model_path = '../grammar_scoring_model.pkl'\njoblib.dump(model, model_path)\nprint(f\"Trained model saved to: {model_path}\")", "outputs": []}]}